FROM python:3.12-slim-bookworm

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    curl \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Set environment variables for PyTorch compatibility
ENV PYTHONUNBUFFERED=1 \
    UVM_ENABLE_LOGGING=1 \
    UV_VERSION=0.7.2 \
    # Apple Silicon MPS support
    PYTORCH_ENABLE_MPS_FALLBACK=1 \
    PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 \
    BLAS=OpenBLAS \
    USE_MPS=1 \
    # NVIDIA CUDA support
    NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Install uv using pip and clear cache
RUN pip install --no-cache-dir "uv==$UV_VERSION"

# Copy the pyproject.toml and uv.lock files from the root directory
COPY ./pyproject.toml ./uv.lock ./

# Install the dependencies and clear cache
RUN uv sync --active --locked \
    && rm -rf ~/.cache/uv/cache/ ~/.cache/uv/artifacts/

# PyTorch installation is handled in the entrypoint script based on detected environment

# Copy source code
COPY ./src/inference_pipeline ./inference_pipeline
COPY ./src/core ./core

# Setup environment variables
ENV PYTHONPATH="/app:${PYTHONPATH}"

# Set entrypoint script that will detect platform and install appropriate PyTorch version
COPY .docker/entrypoint.inference.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

# Expose port for API
EXPOSE 8000

ENTRYPOINT ["/entrypoint.sh"] 